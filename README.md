# Sales-Agent
Agentic AI System for performing sales operations
## ğŸ“˜ `README.md`

```markdown
# ğŸ™ï¸ FastAPI + Streamlit AI Voice Assistant

An end-to-end **Generative AI app** built using **FastAPI (backend)** and **Streamlit (frontend)** for real-time speech-to-text, LLM-based reasoning, and text-to-speech response generation.

This project demonstrates:
- ğŸ§  **FastAPI backend** with Azure / Mistral LLM inference  
- ğŸ¨ **Streamlit frontend** with live microphone input  
- ğŸ”Š **Speech-to-Text (STT)** via `faster-whisper`  
- ğŸ—£ï¸ **Text-to-Speech (TTS)** via `kokoro`  
- âš¡ Real-time API communication between Streamlit and FastAPI using `requests`

---

## ğŸš€ Features
âœ… FastAPI backend serving AI endpoints  
âœ… Streamlit frontend for user interaction  
âœ… Audio recording and playback  
âœ… Real-time LLM responses  
âœ… Ready for Azure or local GPU deployment  

---

## ğŸ§© Project Structure
```

project_folder/

- booking_backend_fastapi.py     # FastAPI backend
- booking_frontend_fast.py       # Streamlit frontend
- requirements.txt               # Dependencies
- env/                           # Virtual environment

````

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone this repository
```bash
git clone https://github.com/<your-username>/<your-repo-name>.git
cd <your-repo-name>
````

### 2ï¸âƒ£ Create and activate virtual environment

```bash
python -m venv env
# Windows
.\env\Scripts\activate
# macOS/Linux
source env/bin/activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

> ğŸ’¡ If you face build issues on Windows (e.g., *Microsoft C++ Build Tools required*),
> install [Build Tools for Visual Studio](https://visualstudio.microsoft.com/visual-cpp-build-tools/).

---

## ğŸ–¥ï¸ Running the Application

### â–¶ï¸ Step 1: Start FastAPI backend

In **Terminal 1**:

```bash
uvicorn booking_backend_fastapi:app --reload --port 8000
```

You should see:

```
INFO:     Uvicorn running on http://127.0.0.1:8000
INFO:     Application startup complete.
```

---

### â–¶ï¸ Step 2: Start Streamlit frontend

In **Terminal 2**:

```bash
streamlit run booking_frontend_fast.py
```

âœ… Streamlit will automatically open in your browser:
[http://localhost:8501](http://localhost:8501)

---

## ğŸ”— Backendâ€“Frontend Connection

Make sure your Streamlit app points to:

```python
BACKEND_URL = "http://127.0.0.1:8000"
```

You can modify this to use your Azure API endpoint or public URL when deploying.

---

## ğŸ§  Example Workflow

1. ğŸ™ï¸ Record or upload your voice in Streamlit
2. ğŸª„ The audio is sent to the FastAPI backend
3. ğŸ§¾ Backend performs:

   * Speech-to-Text (via faster-whisper)
   * Query processing (via Mistral/Azure LLM)
   * Text-to-Speech (via Kokoro)
4. ğŸ”Š The response audio is sent back and played in Streamlit

---

## ğŸ–¼ï¸ Screenshots

### ğŸ§© Streamlit Interface

![Streamlit UI](assets/streamlit_ui.png)

### âš™ï¸ FastAPI Server Running

![FastAPI Terminal](assets/fastapi_terminal.png)

### ğŸ§  Response Example

![Response Output](assets/response_output.png)

*(You can add your own screenshots to `/assets` folder for visual appeal.)*

---

## â˜ï¸ Deployment Options

### ğŸ”¹ Streamlit Cloud

1. Push your repo to GitHub
2. Go to [Streamlit Cloud](https://share.streamlit.io)
3. Deploy the app using your GitHub repo

### ğŸ”¹ Azure App Service

Use this command in Azure CLI:

```bash
az webapp up --name your-app-name --resource-group your-group --sku B1
```

Ensure your `requirements.txt` includes:

```
fastapi
uvicorn
gunicorn
```

---

## ğŸ§° Tech Stack

| Component   | Library/Tool           |
| ----------- | ---------------------- |
| Frontend    | Streamlit              |
| Backend     | FastAPI + Uvicorn      |
| STT         | faster-whisper         |
| TTS         | kokoro                 |
| LLM         | Mistral / Azure OpenAI |
| Audio       | soundfile, playsound   |
| Environment | Python 3.10+           |

---

## ğŸ§ª Sample API Test (Backend)

Use `curl` or `Postman`:

```bash
curl -X POST http://127.0.0.1:8000/process_audio \
  -F "file=@sample.wav"
```

Response:

```json
{
  "transcription": "Hello, how can I help you?",
  "response": "I can assist with your query.",
  "audio_url": "/output/response.wav"
}
```

---

## ğŸ‘¨â€ğŸ’» Author

**Jagadeesh Pamanji**
*Generative AI Engineer*
ğŸ”— [LinkedIn](https://linkedin.com/in/your-profile)
ğŸ“§ [your.email@example.com](mailto:your.email@example.com)

---

## â­ Contribute

Pull requests are welcome!
If you find this project helpful, please give it a â­ on GitHub!

---

## ğŸ›¡ï¸ License

This project is licensed under the **MIT License** â€“ see the [LICENSE](LICENSE) file for details.

```

---

## ğŸª„ Next Steps (optional)
To make this README visually rich:
- Add 3 PNGs in a folder named `/assets`  
  - `streamlit_ui.png`
  - `fastapi_terminal.png`
  - `response_output.png`
- Update image links in README to point to your GitHub repo.

---

Would you like me to **generate those sample screenshots** (`streamlit_ui.png`, `fastapi_terminal.png`, and `response_output.png`) for you so you can directly upload them to GitHub?
```
